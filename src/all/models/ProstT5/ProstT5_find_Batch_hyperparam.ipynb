{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 65.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1, max_batch=1, time=103.11 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:44<00:00, 64.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1, max_batch=64, time=104.18 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:44<00:00, 64.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1, max_batch=4096, time=104.27 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:45<00:00, 63.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1, max_batch=262144, time=105.26 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:44<00:00, 63.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1, max_batch=16777216, time=104.99 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 64.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1, max_batch=1073741824, time=103.87 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 64.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1, max_batch=68719476736, time=103.40 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:42<00:00, 65.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=64, max_batch=1, time=102.49 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:42<00:00, 65.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=64, max_batch=64, time=102.30 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:42<00:00, 65.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=64, max_batch=4096, time=102.68 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:42<00:00, 65.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=64, max_batch=262144, time=102.87 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 65.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=64, max_batch=16777216, time=103.25 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 65.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=64, max_batch=1073741824, time=103.09 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:42<00:00, 65.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=64, max_batch=68719476736, time=102.74 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 64.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=4096, max_batch=1, time=103.38 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [00:56<00:00, 117.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=4096, max_batch=64, time=56.91 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [00:57<00:00, 117.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=4096, max_batch=4096, time=57.11 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [00:57<00:00, 117.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=4096, max_batch=262144, time=57.11 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [00:57<00:00, 117.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=4096, max_batch=16777216, time=57.09 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [00:57<00:00, 117.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=4096, max_batch=1073741824, time=57.01 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [00:57<00:00, 117.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=4096, max_batch=68719476736, time=57.07 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 65.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=262144, max_batch=1, time=103.19 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:   1%|          | 63/6711 [00:00<00:20, 325.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1047893 (L=457)\n",
      "Runtime Error for max_residues=262144, max_batch=64\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  12%|█▏        | 784/6711 [00:00<00:03, 1579.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046347 (L=253)\n",
      "Runtime Error for max_residues=262144, max_batch=4096\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  12%|█▏        | 784/6711 [00:00<00:03, 1614.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046347 (L=253)\n",
      "Runtime Error for max_residues=262144, max_batch=262144\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  12%|█▏        | 784/6711 [00:00<00:03, 1584.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046347 (L=253)\n",
      "Runtime Error for max_residues=262144, max_batch=16777216\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  12%|█▏        | 784/6711 [00:00<00:03, 1746.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046347 (L=253)\n",
      "Runtime Error for max_residues=262144, max_batch=1073741824\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  12%|█▏        | 784/6711 [00:00<00:03, 1769.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046347 (L=253)\n",
      "Runtime Error for max_residues=262144, max_batch=68719476736\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:43<00:00, 65.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=16777216, max_batch=1, time=103.10 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:   1%|          | 63/6711 [00:00<00:11, 570.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1047893 (L=457)\n",
      "Runtime Error for max_residues=16777216, max_batch=64\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  61%|██████    | 4095/6711 [00:01<00:01, 2190.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1048794 (L=108)\n",
      "Runtime Error for max_residues=16777216, max_batch=4096\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2203.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=16777216, max_batch=262144\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2214.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=16777216, max_batch=16777216\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2179.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=16777216, max_batch=1073741824\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2218.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=16777216, max_batch=68719476736\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:42<00:00, 65.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=1073741824, max_batch=1, time=102.19 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:   1%|          | 63/6711 [00:00<00:11, 570.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1047893 (L=457)\n",
      "Runtime Error for max_residues=1073741824, max_batch=64\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  61%|██████    | 4095/6711 [00:01<00:01, 2191.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1048794 (L=108)\n",
      "Runtime Error for max_residues=1073741824, max_batch=4096\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2171.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=1073741824, max_batch=262144\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2216.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=1073741824, max_batch=16777216\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2180.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=1073741824, max_batch=1073741824\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2219.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=1073741824, max_batch=68719476736\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|██████████| 6711/6711 [01:42<00:00, 65.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested max_residues=68719476736, max_batch=1, time=102.76 seconds\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:   1%|          | 63/6711 [00:00<00:11, 577.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1047893 (L=457)\n",
      "Runtime Error for max_residues=68719476736, max_batch=64\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences:  61%|██████    | 4095/6711 [00:01<00:01, 2186.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1048794 (L=108)\n",
      "Runtime Error for max_residues=68719476736, max_batch=4096\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2233.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=68719476736, max_batch=262144\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2174.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=68719476736, max_batch=16777216\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2199.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=68719476736, max_batch=1073741824\n",
      "Loading ProsT5 from: Rostlab/ProstT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Embedding sequences: 100%|█████████▉| 6710/6711 [00:03<00:00, 2221.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError during embedding for 1046789 (L=14)\n",
      "Runtime Error for max_residues=68719476736, max_batch=68719476736\n",
      "Best parameters: max_residues=4096, max_batch=64 with time=56.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/ku76797/Documents/internship/Work/CATHe')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(\"Using device: {}\".format(device))\n",
    "\n",
    "\n",
    "def get_T5_model(model_dir):\n",
    "    print(\"Loading ProsT5 from: {}\".format(model_dir))\n",
    "    model = T5EncoderModel.from_pretrained(model_dir).to(device)\n",
    "    model = model.eval()\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_dir, do_lower_case=False)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def read_csv(seq_path):\n",
    "    '''\n",
    "        Reads in CSV file containing sequences.\n",
    "        Returns a dictionary of sequences with IDs as keys.\n",
    "    '''\n",
    "    sequences = {}\n",
    "    df = pd.read_csv(seq_path)\n",
    "    for _, row in df.iterrows():\n",
    "        sequences[int(row['Unnamed: 0'])] = row['Sequence']\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def get_embeddings(seq_path, model_dir, half_precision, is_3Di,\n",
    "                   max_residues, max_seq_len, max_batch):\n",
    "    \n",
    "    emb_dict = dict()\n",
    "\n",
    "    # Read in CSV\n",
    "    seq_dict = read_csv(seq_path)\n",
    "    prefix = \"<fold2AA>\" if is_3Di else \"<AA2fold>\"\n",
    "    \n",
    "    model, tokenizer = get_T5_model(model_dir)\n",
    "    if half_precision:\n",
    "        model = model.half()\n",
    "\n",
    "    # sort sequences by length to trigger OOM at the beginning\n",
    "    seq_dict = sorted(seq_dict.items(), key=lambda kv: len(kv[1]), reverse=True)\n",
    "    \n",
    "    start = time.time()\n",
    "    batch = list()\n",
    "    for seq_idx, (pdb_id, seq) in enumerate(tqdm(seq_dict, desc=\"Embedding sequences\"), 1):\n",
    "        # replace non-standard AAs\n",
    "        seq = seq.replace('U', 'X').replace('Z', 'X').replace('O', 'X').replace('B', 'X')\n",
    "        seq_len = len(seq)\n",
    "        seq = prefix + ' ' + ' '.join(list(seq))\n",
    "        batch.append((pdb_id, seq, seq_len))\n",
    "\n",
    "        # count residues in current batch and add the last sequence length to\n",
    "        # avoid that batches with (n_res_batch > max_residues) get processed \n",
    "        n_res_batch = sum([s_len for _, _, s_len in batch]) + seq_len \n",
    "        if len(batch) >= max_batch or n_res_batch >= max_residues or seq_idx == len(seq_dict) or seq_len > max_seq_len:\n",
    "            pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "            batch = list()\n",
    "\n",
    "            token_encoding = tokenizer.batch_encode_plus(seqs, \n",
    "                                                     add_special_tokens=True, \n",
    "                                                     padding=\"longest\", \n",
    "                                                     return_tensors='pt'\n",
    "                                                     ).to(device)\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    embedding_repr = model(token_encoding.input_ids, \n",
    "                                           attention_mask=token_encoding.attention_mask)\n",
    "            except RuntimeError:\n",
    "                print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "                return None\n",
    "\n",
    "            # batch-size x seq_len x embedding_dim\n",
    "            # extra token is added at the end of the seq\n",
    "            for batch_idx, identifier in enumerate(pdb_ids):\n",
    "                s_len = seq_lens[batch_idx]\n",
    "                # account for prefix in offset\n",
    "                emb = embedding_repr.last_hidden_state[batch_idx, 1:s_len+1]\n",
    "                \n",
    "                \n",
    "                emb = emb.mean(dim=0)\n",
    "                emb_dict[identifier] = emb.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    if len(emb_dict) != len(seq_dict):\n",
    "        return None\n",
    "\n",
    "    total_time = end - start\n",
    "    return total_time\n",
    "\n",
    "def find_best_params(seq_path, model_dir, half_precision=True, is_3Di=False, max_seq_len=3263):\n",
    "    max_residues_values = [2**i for i in range(6, 14, 2)]  \n",
    "    max_batch_values = [2**i for i in range(6, 14, 2)] \n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for max_residues in max_residues_values:\n",
    "        for max_batch in max_batch_values:\n",
    "            try:\n",
    "                total_time = get_embeddings(seq_path, model_dir, half_precision, is_3Di, max_residues, max_seq_len, max_batch)\n",
    "                if total_time is None:\n",
    "                    results.append((max_residues, max_batch, \"Runtime Error\"))\n",
    "                    print(f\"Runtime Error for max_residues={max_residues}, max_batch={max_batch}\")\n",
    "                    continue  # Skip to the next iteration if total_time is None\n",
    "                results.append((max_residues, max_batch, total_time))\n",
    "                print(f\"Tested max_residues={max_residues}, max_batch={max_batch}, time={total_time:.2f} seconds\")\n",
    "            except MemoryError:\n",
    "                results.append((max_residues, max_batch, \"Memory Error\"))\n",
    "                print(f\"Memory Error for max_residues={max_residues}, max_batch={max_batch}\")\n",
    "            except Exception as e:\n",
    "                results.append((max_residues, max_batch, f\"Error: {e}\"))\n",
    "                print(f\"Failed max_residues={max_residues}, max_batch={max_batch} with error: {e}\")\n",
    "    \n",
    "    # Find the best parameters\n",
    "    valid_results = [result for result in results if isinstance(result[2], (int, float))]\n",
    "    if valid_results:\n",
    "        best_params = min(valid_results, key=lambda x: x[2])\n",
    "        print(f\"Best parameters: max_residues={best_params[0]}, max_batch={best_params[1]} with time={best_params[2]:.2f} seconds\")\n",
    "    else:\n",
    "        print(\"No valid parameter combinations found.\")\n",
    "    \n",
    "    return results, best_params if valid_results else None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    seq_path = \"./data/Dataset/csv/Val.csv\"\n",
    "    \n",
    "    results, best_params = find_best_params(seq_path, model_dir=\"Rostlab/ProstT5\", half_precision=True, is_3Di=False)\n",
    "    \n",
    "    # Optionally, save the results to a file for later analysis\n",
    "    results_df = pd.DataFrame(results, columns=[\"max_residues\", \"max_batch\", \"time\"])\n",
    "    results_df.to_csv(\"./src/all/models/ProstT5/embedding_time_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
